import openpyxl
from pathlib import Path
from datetime import datetime
import pandas as pd

# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def get_unique_path(path: Path) -> Path:
    """åŒåãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€(1),(2)... ã‚’ä»˜ã‘ã¦é‡è¤‡å›é¿ã™ã‚‹"""
    if not path.exists():
        return path
    stem, suffix, parent = path.stem, path.suffix, path.parent
    i = 1
    while True:
        candidate = parent / f"{stem}({i}){suffix}"
        if not candidate.exists():
            return candidate
        i += 1

def parse_row_list_file(filepath: Path):
    """row_list_*.txt ã‚’è§£æã—ã€(diff_URL, filterling_URL) ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()
    blocks = [b.strip() for b in content.split("--- row_start ---") if b.strip()]
    results = []
    for block in blocks:
        lines = [line.strip() for line in block.splitlines() if line.strip()]
        diff_urls, filter_urls = [], []
        if "diff_URL:" in lines:
            diff_start = lines.index("diff_URL:") + 1
            if "filterling_URL:" in lines:
                filter_start = lines.index("filterling_URL:")
                diff_urls = lines[diff_start:filter_start]
                filter_urls = lines[filter_start + 1:]
            else:
                diff_urls = lines[diff_start:]
                filter_urls = []
        # ãƒã‚¤ã‚ºé™¤å»
        filter_urls = [u for u in filter_urls if u != "ï¼ˆãªã—ï¼‰" and not u.startswith("--- row_start ---")]
        results.append(("\n".join(diff_urls), "\n".join(filter_urls)))
    return results

def find_latest_sparse_log(base_dir: Path, genre: str) -> Path | None:
    """
    base_dirï¼ˆ=ãƒ•ã‚¡ã‚¤ãƒ«AãŒã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰ç›´ä¸‹ log_Searched/ ã‹ã‚‰ã€
    searched(genre)_Keyword-list_*__log_*.xlsxï¼ˆor .csvï¼‰ ã®æœ€æ–°ã‚’è¿”ã™
    """
    log_dir = base_dir / "log_Searched"
    if not log_dir.exists():
        return None
    patterns = [
        f"searched({genre})_Keyword-list_*__log_*.xlsx",
        f"searched({genre})_Keyword-list_*__log_*.csv",
    ]
    cands = []
    for pat in patterns:
        cands.extend(sorted(log_dir.glob(pat)))
    if not cands:
        return None
    def parse_ts(p: Path):
        try:
            ts = p.stem.split("__log_")[-1]
            return datetime.strptime(ts, "%Y%m%d-%H%M%S")
        except Exception:
            return datetime.fromtimestamp(p.stat().st_mtime)
    cands.sort(key=parse_ts, reverse=True)
    return cands[0]

# =========================
# â‘  åŒéšå±¤ã®ã€Œãƒ•ã‚©ãƒ«ãƒ€ã€ã‚’åˆ—æŒ™ã—ã¦é¸æŠï¼ˆallãªã—ãƒ»è¤‡æ•°ç•ªå·OKï¼‰
# =========================
SCRIPT_DIR = Path(__file__).resolve().parent
dirs_1depth = sorted([p for p in SCRIPT_DIR.iterdir() if p.is_dir()])
if not dirs_1depth:
    raise FileNotFoundError("åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ç›´ä¸‹ã«ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

print("è»¢è¨˜å¯¾è±¡ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„:")
for i, d in enumerate(dirs_1depth, start=1):
    print(f"{i}: {d.name}")
n_dirs = len(dirs_1depth)
raw_dir_pick = input(f"ç•ªå·ï¼ˆ1ã€œ{n_dirs}ã€‚ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°å¯ï¼‰: ").strip()
dir_idxs = sorted({int(x.strip()) for x in raw_dir_pick.split(",") if x.strip().isdigit()})
if not dir_idxs:
    raise ValueError(f"ãƒ•ã‚©ãƒ«ãƒ€ç•ªå·ã®å…¥åŠ›ãŒä¸æ­£ã§ã™ã€‚1ã€œ{n_dirs} ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
target_dirs = [dirs_1depth[i-1] for i in dir_idxs if 1 <= i <= n_dirs]

# =========================
# â‘¡ å„ãƒ•ã‚©ãƒ«ãƒ€ã§ row_list_*.txt ã‚’é¸æŠï¼ˆallãªã—ãƒ»è¤‡æ•°ç•ªå·OKï¼‰
# â‘¢ è»¢è¨˜å…ˆ Excel ã¯ æ¥é ­è¾ "Keyword-list_" ã‚’è‡ªå‹•é¸æŠ
# â‘£ TXTã®å†…å®¹ã‚’å¯¾è±¡ã‚·ãƒ¼ãƒˆã«è»¢è¨˜ã—ã€å¯¾è±¡ã‚·ãƒ¼ãƒˆã ã‘ã®æ–°è¦ãƒ–ãƒƒã‚¯ã‚’
#    ã€Œtrsc(ã€‡ã€‡)_ã€å½¢å¼ã§ä¿å­˜ã€‚
#    è»¢è¨˜å…ˆè¡Œã¯ã€row_list_* ã® * éƒ¨åˆ†ï¼ˆ=å°åˆ†é¡åï¼‰ã«åˆè‡´ã™ã‚‹
#    æœ€æ–°ã®ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ­ã‚° D ã® processed_at è¡Œã‚’**å‚ç…§**ã—ã¦æ±ºå®šã€‚
# =========================
for base_dir in target_dirs:
    # --- row_list_*.txt ã‚’åˆ—æŒ™ ---
    row_list_files = sorted(base_dir.glob("row_list_*.txt"))
    if not row_list_files:
        print(f"[WARN] ãƒ•ã‚©ãƒ«ãƒ€ '{base_dir.name}' ã« row_list_*.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        continue

    print("\n" + "="*72)
    print(f"â–¶ ãƒ•ã‚©ãƒ«ãƒ€: {base_dir.name}")
    print("è»¢è¨˜å…ƒã® TXT ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    for i, f in enumerate(row_list_files, start=1):
        print(f"{i}: {f.name}")
    n_txt = len(row_list_files)
    raw_txt_pick = input(f"ç•ªå·ï¼ˆ1ã€œ{n_txt}ã€‚ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°å¯ï¼‰: ").strip()
    txt_idxs = sorted({int(x.strip()) for x in raw_txt_pick.split(",") if x.strip().isdigit()})
    if not txt_idxs:
        print(f"[WARN] TXTã®ç•ªå·å…¥åŠ›ãŒç©º or ä¸æ­£ã§ã™ï¼ˆ1ã€œ{n_txt}ï¼‰ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        continue
    target_txts = [row_list_files[i-1] for i in txt_idxs if 1 <= i <= n_txt]

    # --- è»¢è¨˜å…ˆã® Excel ã‚’è‡ªå‹•é¸æŠ: æ¥é ­è¾ "Keyword-list_" ã®ã¿å¯¾è±¡ ---
    excel_candidates = sorted(base_dir.glob("Keyword-list_*.xlsx"))
    if not excel_candidates:
        print(f"[WARN] ãƒ•ã‚©ãƒ«ãƒ€ '{base_dir.name}' ã« 'Keyword-list_*.xlsx' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        continue

    print("\nè‡ªå‹•é¸æŠã•ã‚ŒãŸè»¢è¨˜å…ˆ Excelï¼ˆKeyword-list_*ï¼‰:")
    for i, f in enumerate(excel_candidates, start=1):
        print(f"{i}: {f.name}")

    # --- TXTç¾¤ Ã— Excelç¾¤ ã§å‡¦ç† ---
    for excel_path in excel_candidates:
        print("\n" + "-"*72)
        print(f"â–¶ è»¢è¨˜å…ˆ Excel: {excel_path.name}")

        for txt_path in target_txts:
            sheet_name_candidate = txt_path.stem.replace("row_list_", "").strip()
            print(f"  - TXT: {txt_path.name} â†’ ã‚·ãƒ¼ãƒˆå€™è£œ: '{sheet_name_candidate}'")

            # 1) TXTèª­ã¿è¾¼ã¿
            row_sets = parse_row_list_file(txt_path)

            # 2) Excel ã‚’èª­ã¿è¾¼ã¿
            wb = openpyxl.load_workbook(excel_path)

            # 3) ã‚·ãƒ¼ãƒˆå å®Œå…¨ä¸€è‡´ï¼ˆå‰å¾Œç©ºç™½ãƒˆãƒªãƒ ï¼‰
            match_name = next((n for n in wb.sheetnames if n.strip() == sheet_name_candidate), None)
            if not match_name:
                print(f"    âœ– ã‚·ãƒ¼ãƒˆ '{sheet_name_candidate}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                continue

            ws = wb[match_name]
            print(f"    âœ… å¯¾è±¡ã‚·ãƒ¼ãƒˆ: {ws.title}")

            # 4) å¿…é ˆåˆ—ç¢ºèªï¼ˆç„¡ã‘ã‚Œã°ä½œæˆï¼‰
            headers = {cell.value: col_idx for col_idx, cell in enumerate(ws[1], start=1)}
            changed = False
            for need in ["diff_URL", "filterling_URL"]:
                if need not in headers:
                    ws.cell(row=1, column=ws.max_column + 1).value = need
                    headers[need] = ws.max_column
                    changed = True
            if changed:
                headers = {cell.value: col_idx for col_idx, cell in enumerate(ws[1], start=1)}

            diff_col = headers["diff_URL"]
            filter_col = headers["filterling_URL"]

            # 5) å‚ç…§ãƒ­ã‚°ã‹ã‚‰ã€Œè»¢è¨˜å…ˆè¡Œã€ã‚’æ±ºå®š
            genre = sheet_name_candidate
            latest_log = find_latest_sparse_log(excel_path.parent, genre)
            if latest_log is None:
                print("    âš  å‚ç…§ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å¾“æ¥ã©ãŠã‚Šå…ˆé ­ã‹ã‚‰é †ã«è»¢è¨˜ã—ã¾ã™ã€‚")
                target_rows = list(range(2, 2 + len(row_sets)))  # 2è¡Œç›®ã‹ã‚‰
            else:
                print(f"    â†ª å‚ç…§ãƒ­ã‚°: {latest_log.name}")
                if latest_log.suffix.lower() == ".xlsx":
                    dfl = pd.read_excel(latest_log, sheet_name=sheet_name_candidate)
                else:
                    dfl = pd.read_csv(latest_log)
                if "processed_at" not in dfl.columns:
                    print("    âš  ãƒ­ã‚°ã« 'processed_at' åˆ—ãŒãªã„ãŸã‚ã€å…ˆé ­ã‹ã‚‰é †ã«è»¢è¨˜ã—ã¾ã™ã€‚")
                    target_rows = list(range(2, 2 + len(row_sets)))
                else:
                    processed_idx = [int(i) for i, v in enumerate(dfl["processed_at"].fillna("").tolist()) if str(v).strip() != ""]
                    target_rows = [i + 2 for i in processed_idx]  # 1è¡Œç›®ãŒãƒ˜ãƒƒãƒ€
                    if not target_rows:
                        print("    âš  ãƒ­ã‚°ã«å‡¦ç†è¡ŒãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å…ˆé ­ã‹ã‚‰é †ã«è»¢è¨˜ã—ã¾ã™ã€‚")
                        target_rows = list(range(2, 2 + len(row_sets)))

            # è»¢è¨˜æ•°ã¯è¡Œãƒªã‚¹ãƒˆã¨TXTå´ã®æœ€å°ã«åˆã‚ã›ã‚‹
            n_write = min(len(row_sets), len(target_rows))
            if n_write == 0:
                print("    âš  è»¢è¨˜å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                continue

            # 6) æŒ‡å®šè¡Œã«è»¢è¨˜ï¼ˆä¸Šæ›¸ãï¼‰
            written = 0
            for k in range(n_write):
                tgt_row = target_rows[k]
                diff_str, filter_str = row_sets[k]
                ws.cell(row=tgt_row, column=diff_col).value = diff_str
                ws.cell(row=tgt_row, column=filter_col).value = filter_str
                written += 1

            print(f"    ğŸ“ æ›¸ãè¾¼ã‚“ã è¡Œæ•°: {written}ï¼ˆTXT {len(row_sets)}ä»¶ / ãƒ­ã‚°è¡Œ {len(target_rows)}ä»¶ â†’ ä½¿ç”¨ {n_write}ä»¶ï¼‰")

            # 7) å¯¾è±¡ã‚·ãƒ¼ãƒˆã ã‘ã®æ–°è¦ãƒ–ãƒƒã‚¯ã‚’ä½œæˆã—ä¿å­˜ï¼ˆtrsc(ã€‡ã€‡)_ï¼‰
            new_wb = openpyxl.Workbook()
            default_ws = new_wb.active
            new_wb.remove(default_ws)

            nws = new_wb.create_sheet(ws.title)
            for r_idx, row in enumerate(ws.iter_rows(values_only=True), start=1):
                for c_idx, v in enumerate(row, start=1):
                    nws.cell(row=r_idx, column=c_idx).value = v

            out_name = f"trsc({ws.title})_{excel_path.name}"
            out_path = get_unique_path(excel_path.parent / out_name)
            new_wb.save(out_path)
            print(f"    ğŸ’¾ ä¿å­˜ï¼ˆå¯¾è±¡ã‚·ãƒ¼ãƒˆã®ã¿ï¼‰: {out_path}")

    print("\nå®Œäº†ã—ã¾ã—ãŸã€‚")
